{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 13-1 Learning Notebook: Intro to ML Pipelines\n",
    "The goal of this teching notebook is to explain how a pipeline works in ML. <P>\n",
    "    \n",
    "A machine learning pipeline is a way to codify and automate the workflow it takes to produce a machine learning model. Machine learning pipelines consist of multiple sequential steps that do everything from data extraction and preprocessing to model training and deployment.  We will just use the basics.\n",
    "\n",
    "**Data:**\n",
    "    \n",
    "The data used in this problem is a simplified version of using \"gene expression\" to predict cancer in people. It is based on this dataset:\n",
    "- http://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq\n",
    "\n",
    "In this data, there are 6 genes that are each represented by a floating point number. The target value is 'cancer_detected' which is 0 = false and 1 = true.<P>\n",
    "    \n",
    "The goal is to use a classification algorithm to predict cancer based on the values of the genes.<P>\n",
    "    \n",
    "Our method:\n",
    "1. Load, isolate and split the data\n",
    "2. Define the steps in the pipeline\n",
    "3. Create the pipeline\n",
    "4. Use the pipeline to transform and train your model\n",
    "5. Evaluate the result\n",
    "6. Bring it all together using a different set of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load, isolate and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>gene3</th>\n",
       "      <th>gene4</th>\n",
       "      <th>gene5</th>\n",
       "      <th>gene6</th>\n",
       "      <th>cancer_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759334</td>\n",
       "      <td>27.342287</td>\n",
       "      <td>118.878384</td>\n",
       "      <td>-29.800470</td>\n",
       "      <td>641.214491</td>\n",
       "      <td>-12.905525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.726902</td>\n",
       "      <td>16.190669</td>\n",
       "      <td>122.519870</td>\n",
       "      <td>-56.616092</td>\n",
       "      <td>239.289030</td>\n",
       "      <td>107.212129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.234535</td>\n",
       "      <td>19.345805</td>\n",
       "      <td>128.827574</td>\n",
       "      <td>-90.478848</td>\n",
       "      <td>374.459500</td>\n",
       "      <td>55.037188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.922451</td>\n",
       "      <td>20.416719</td>\n",
       "      <td>57.906599</td>\n",
       "      <td>-62.897717</td>\n",
       "      <td>398.818805</td>\n",
       "      <td>146.694338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.227942</td>\n",
       "      <td>26.415990</td>\n",
       "      <td>87.027782</td>\n",
       "      <td>-38.962616</td>\n",
       "      <td>581.078233</td>\n",
       "      <td>26.624324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene1      gene2       gene3      gene4       gene5       gene6  \\\n",
       "0  0.759334  27.342287  118.878384 -29.800470  641.214491  -12.905525   \n",
       "1  3.726902  16.190669  122.519870 -56.616092  239.289030  107.212129   \n",
       "2  2.234535  19.345805  128.827574 -90.478848  374.459500   55.037188   \n",
       "3  4.922451  20.416719   57.906599 -62.897717  398.818805  146.694338   \n",
       "4  1.227942  26.415990   87.027782 -38.962616  581.078233   26.624324   \n",
       "\n",
       "   cancer_detected  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load df from S3 .csv\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3') \n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/gene-cancer-small.csv'\n",
    "response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "df = pd.read_csv(response.get(\"Body\"))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>gene3</th>\n",
       "      <th>gene4</th>\n",
       "      <th>gene5</th>\n",
       "      <th>gene6</th>\n",
       "      <th>cancer_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.117973</td>\n",
       "      <td>20.732453</td>\n",
       "      <td>82.764879</td>\n",
       "      <td>-50.003120</td>\n",
       "      <td>408.900251</td>\n",
       "      <td>112.913532</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.540117</td>\n",
       "      <td>4.111156</td>\n",
       "      <td>32.476013</td>\n",
       "      <td>21.672628</td>\n",
       "      <td>164.818999</td>\n",
       "      <td>48.643582</td>\n",
       "      <td>0.468826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.253117</td>\n",
       "      <td>10.724020</td>\n",
       "      <td>15.323295</td>\n",
       "      <td>-127.539620</td>\n",
       "      <td>26.890555</td>\n",
       "      <td>-12.905525</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.238394</td>\n",
       "      <td>17.776597</td>\n",
       "      <td>61.068330</td>\n",
       "      <td>-60.886868</td>\n",
       "      <td>284.871681</td>\n",
       "      <td>83.468788</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.588480</td>\n",
       "      <td>20.462301</td>\n",
       "      <td>81.359593</td>\n",
       "      <td>-48.004696</td>\n",
       "      <td>407.236999</td>\n",
       "      <td>120.271416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.173925</td>\n",
       "      <td>23.642621</td>\n",
       "      <td>106.615862</td>\n",
       "      <td>-39.194564</td>\n",
       "      <td>526.621934</td>\n",
       "      <td>151.744827</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.146552</td>\n",
       "      <td>29.389300</td>\n",
       "      <td>150.491443</td>\n",
       "      <td>9.133850</td>\n",
       "      <td>813.139351</td>\n",
       "      <td>206.951441</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene1       gene2       gene3       gene4       gene5       gene6  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean     4.117973   20.732453   82.764879  -50.003120  408.900251  112.913532   \n",
       "std      1.540117    4.111156   32.476013   21.672628  164.818999   48.643582   \n",
       "min     -0.253117   10.724020   15.323295 -127.539620   26.890555  -12.905525   \n",
       "25%      3.238394   17.776597   61.068330  -60.886868  284.871681   83.468788   \n",
       "50%      4.588480   20.462301   81.359593  -48.004696  407.236999  120.271416   \n",
       "75%      5.173925   23.642621  106.615862  -39.194564  526.621934  151.744827   \n",
       "max      7.146552   29.389300  150.491443    9.133850  813.139351  206.951441   \n",
       "\n",
       "       cancer_detected  \n",
       "count       100.000000  \n",
       "mean          0.320000  \n",
       "std           0.468826  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           1.000000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the scales of the features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (80, 6)\n",
      "y_train: (80,)\n",
      "X_test: (20, 6)\n",
      "y_test: (20,)\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "X = df.drop(['cancer_detected'],axis = 1)\n",
    "# Target\n",
    "y = df['cancer_detected']\n",
    "# Split into train/test\n",
    "# Reserve 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state = 42)\n",
    "# Verify the sizes of the split datasets\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the steps in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       " ('LogRegClassifier',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipelines consist of sequential steps. The are technically a 'list of tuples'.\n",
    "#\n",
    "#    https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "#\n",
    "# Step 1: scale the data using the normalization (MinMaxScaler) scaler\n",
    "# Step 2: fit it a logistic regression model\n",
    "#\n",
    "\n",
    "norm_scaler = MinMaxScaler()\n",
    "logReg = LogisticRegression()\n",
    "\n",
    "steps = [('Normalizer', norm_scaler), ('LogRegClassifier', logReg)]\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('LogRegClassifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "pipe = Pipeline(steps)\n",
    "pipe # Show parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is happening?\n",
    "A pipeline is a list of data transforms and a final estimator.<P>\n",
    "    \n",
    "Remember, our normailzation scaler has two methods: **.fit()** and **.transform()**. These are requirements for every step except the last step.<P>\n",
    "\n",
    "The method sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the pipeline to scale your data and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('LogRegClassifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, perform the pipeline steps on the data\n",
    "# The end result is a trained model\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16,  0],\n",
       "       [ 2,  2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat the pipe object just like trained model\n",
    "y_pred = pipe.predict(X_test)\n",
    "print('Accuracy:', pipe.score(X_test, y_test))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bring it all together using a different set of steps\n",
    "This can be a very efficient way to work with ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16,  0],\n",
       "       [ 1,  3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different: standardize the data and use the GBC algorithm\n",
    "\n",
    "stand_scaler = StandardScaler()\n",
    "GB_classifier = GradientBoostingClassifier()\n",
    "#\n",
    "steps = [('std_scaler', stand_scaler), ('gbd', GB_classifier)]\n",
    "#\n",
    "# Combine creation and fit together\n",
    "pipe = Pipeline(steps).fit(X_train, y_train)\n",
    "# Accuracy\n",
    "y_pred = pipe.predict(X_test)\n",
    "print('Accuracy:', pipe.score(X_test, y_test))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the basics. A pipeline can streamline the steps needed to prepare the data, train and evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
