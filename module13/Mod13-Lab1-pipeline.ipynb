{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 13-Lab 1: Practice Pipelines\n",
    "\n",
    "Use the pipeline to scale the data and fit a different algorithm: XGB\n",
    "\n",
    "**Data:**\n",
    "    \n",
    "The data used in this problem is a simplified version of using \"gene expression\" to predict cancer in people. It is based on this dataset:\n",
    "- http://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq\n",
    "\n",
    "In this data, there are 6 genes that are each represented by a floating point number. The target value is 'cancer_detected' which is 0 = false and 1 = true.<P>\n",
    "    \n",
    "The goal is to use a classification algorithm to predict cancer based on the values of the genes.<P>\n",
    "    \n",
    "Our method:\n",
    "1. Load, isolate and split the data\n",
    "2. Define the steps in the pipeline\n",
    "3. Create the pipeline\n",
    "4. Use the pipeline to transform and train your model\n",
    "5. Evaluate the result\n",
    "6. Predict on new, unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to install XGBOOST every time we restart our instanace\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load, isolate and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df from S3 .csv\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3') \n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/gene-cancer-small.csv'\n",
    "response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "df = pd.read_csv(response.get(\"Body\"))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the scales of the features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df.drop(['cancer_detected'],axis = 1)\n",
    "# Target\n",
    "y = df['cancer_detected']\n",
    "# Split into train/test\n",
    "# Reserve 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state = 42)\n",
    "# Verify the sizes of the split datasets\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the steps in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines consist of sequential steps. The are technically a 'list of tuples'.\n",
    "#\n",
    "#    https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "#\n",
    "# Step 1: scale the data using the normalization or standardization scaler\n",
    "# Step 2: fit a xgb model\n",
    "#\n",
    "\n",
    "scaler = \"what scaler will you use?\"\n",
    "xgbc = \"how do you create an xgboost classifier model?\" # We did this in a previous module\n",
    "\n",
    "steps = [('Scaler', scaler), ('XGB', xgbc)]\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the pipeline to scale and train your model\n",
    "hint: Use the fit() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the result\n",
    "- Use your trained model to predict on the X_test dataset\n",
    "- Calculate the accuracy of the model\n",
    "- Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict on new, unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new patient had these gene numbers\n",
    "X_unseen = pd.DataFrame(data = [[2.2, 25.5, 55.55, -20.1, 355.8, 180.0]],columns = X_test.columns)\n",
    "X_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the model predict they will get cancer?\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
