{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. List all S3 buckets our account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athena-ime312-data\n",
      "athena-ime312-results\n",
      "cf-templates-1557tsq4h6qye-us-west-2\n",
      "custom-labels-console-us-east-1-7816f32253\n",
      "custom-labels-console-us-west-2-1e5e5a5693\n",
      "forecastbucket-1m2t9x653tz4n\n",
      "ftp-dlink-cam1\n",
      "gse580-read-only\n",
      "kcolvintemp\n",
      "machinelearning-read-only\n",
      "machinelearning-shared\n",
      "msba-rekognition\n",
      "sagemaker-us-west-2-460996044744\n",
      "sbc-imagery\n",
      "temp-235612\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import boto3\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3')\n",
    "response = s3.list_buckets()\n",
    "for buck in response['Buckets']:\n",
    "    print(buck['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. List all files in the 'machinelearning-read-only' bucket\n",
    "Hint: Find the 'list_objects' function in the boto3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/data.csv\n",
      "notebooks/\n",
      "notebooks/boto3.ipynb\n",
      "notebooks/s3.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "bucket = 'machinelearning-read-only'\n",
    "response = s3.list_objects(Bucket = bucket)\n",
    "# The response structure is a little complicated, so careful how you parse it\n",
    "for item in response['Contents']: # This is a list\n",
    "    print(item['Key']) # For each item in the list, print the value of the 'Key' key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download the file 'data/data.csv' to your local directory.\n",
    "Hint: You'll need to find the documentation for the S3 client 'download_file()' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response was: None\n",
      "What is the type of the response? <class 'NoneType'>\n",
      "\n",
      "Tried to copy a file that doesn't exist:  An error occurred (404) when calling the HeadObject operation: Not Found\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "key = 'data/data.csv'\n",
    "response = s3.download_file(bucket, key, 'data.csv')\n",
    "# This is unusual that it doesn't return anything;\n",
    "print(\"The response was:\",response)\n",
    "print('What is the type of the response?',type(response))\n",
    "# But, if there was an error, we'd know about it:\n",
    "try:\n",
    "    response = s3.download_file(bucket, 'data/data2.csv', 'data.csv') # data/data2.csv doesn't exist\n",
    "except Exception as e:\n",
    "    print(\"\\nTried to copy a file that doesn't exist: \",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Upload a file to a S3 bucket\n",
    "- rename your local file 'data.csv' to 'your_username-data.csv' (e.g. kcolvin-data.csv)\n",
    "- upload that file to the bucket called 'machinelearning-shared'\n",
    "- locate it in the 'data' folder<P>\n",
    "\n",
    "<B>Hints:</B>\n",
    "- you'll need to find the right function from the boto3 's3' client documentation\n",
    "- you'll need to make sure your key locates the file correctly (e.g., 'data/kcolvin-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OK, it worked.\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "bucket = 'machinelearning-shared'\n",
    "key = 'data/kcolvin-data.csv'\n",
    "try:\n",
    "    response = s3.upload_file('kcolvin-data.csv', bucket, key)\n",
    "    print('All OK, it worked.')\n",
    "except Exception as e:\n",
    "    print(\"\\nSomething went wrong: \",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Delete S3 the file you just uploaded\n",
    "Hints: \n",
    "- delete_object() is the function you will need\n",
    "- Veryify you deleted the object by listing all objects in the 'machinelearning-shared' bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "response = s3.delete_object(Bucket = bucket, Key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dkraker-data.csv\n"
     ]
    }
   ],
   "source": [
    "bucket = 'machinelearning-shared'\n",
    "response = s3.list_objects(Bucket = bucket)\n",
    "# The response structure is a little complicated, so careful how you parse it\n",
    "for item in response['Contents']: # This is a list\n",
    "    print(item['Key']) # For each item in the list, print the value of the 'Key' key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
