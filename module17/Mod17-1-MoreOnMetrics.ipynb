{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 17: Learning Notebook: More on Evaluation Metrics\n",
    "\n",
    "Let's introduce some new classification metrics:\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Classification Report\n",
    "\n",
    "These are building toward even better stuff in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and investigate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df size (rows, columns): (1000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>gene3</th>\n",
       "      <th>gene4</th>\n",
       "      <th>gene5</th>\n",
       "      <th>gene6</th>\n",
       "      <th>cancer_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.447535</td>\n",
       "      <td>14.196807</td>\n",
       "      <td>80.524611</td>\n",
       "      <td>-36.487496</td>\n",
       "      <td>289.932591</td>\n",
       "      <td>146.273690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.276234</td>\n",
       "      <td>17.705782</td>\n",
       "      <td>72.786907</td>\n",
       "      <td>-63.487129</td>\n",
       "      <td>293.618375</td>\n",
       "      <td>90.953863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.036522</td>\n",
       "      <td>14.942696</td>\n",
       "      <td>67.819683</td>\n",
       "      <td>-48.681795</td>\n",
       "      <td>249.619909</td>\n",
       "      <td>165.576714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene1      gene2      gene3      gene4       gene5       gene6  \\\n",
       "0  3.447535  14.196807  80.524611 -36.487496  289.932591  146.273690   \n",
       "1  3.276234  17.705782  72.786907 -63.487129  293.618375   90.953863   \n",
       "2  4.036522  14.942696  67.819683 -48.681795  249.619909  165.576714   \n",
       "\n",
       "   cancer_detected  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from S3\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3') \n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/cancer-10.csv' \n",
    "response = s3.get_object(Bucket = source_bucket, Key = source_key)\n",
    "df = pd.read_csv(response.get(\"Body\"))\n",
    "print('df size (rows, columns):',df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    899\n",
       "1    101\n",
       "Name: cancer_detected, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cancer_detected'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (800, 6)\n",
      "y_train: (800,)\n",
      "X_test: (200, 6)\n",
      "y_test: (200,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df.drop(['cancer_detected'], axis = 1)\n",
    "y = df['cancer_detected']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state = 7)\n",
    "# Verify the sizes of the split datasets\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.905\n"
     ]
    }
   ],
   "source": [
    "# Logitic Regression\n",
    "scaler = StandardScaler() # Standardize the data\n",
    "lr = LogisticRegression()\n",
    "steps = [('Scaler', scaler), ('LogReg', lr)]\n",
    "pipe = Pipeline(steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Logistic Regression accuracy:', round(acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall the confusion matrix\n",
    "<P>\n",
    "<img src=\"images/cm.png\" width=200 height=200 /><BR>\n",
    "True Positive (TP) \n",
    "\n",
    "    The predicted value matches the actual value\n",
    "    The actual value was positive and the model predicted a positive value\n",
    "\n",
    "True Negative (TN) \n",
    "\n",
    "    The predicted value matches the actual value\n",
    "    The actual value was negative and the model predicted a negative value\n",
    "\n",
    "False Positive (FP) – Type 1 error\n",
    "\n",
    "    The predicted value was falsely predicted\n",
    "    The actual value was negative but the model predicted a positive value\n",
    "    Also known as the Type 1 error\n",
    "\n",
    "False Negative (FN) – Type 2 error\n",
    "\n",
    "    The predicted value was falsely predicted\n",
    "    The actual value was positive but the model predicted a negative value\n",
    "    Also known as the Type 2 error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    182\n",
       "1     18\n",
       "Name: cancer_detected, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True values from the test dataset\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197\n",
       "1      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values from the logistic regression algorithm\n",
    "pd.DataFrame(data = y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  17],\n",
       "       [  2, 180]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot our confusion matrix for 1 = cancer detected and 0 = no cancer detected\n",
    "confusion_matrix(y_test, y_pred,labels = [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 2, 180)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store each value in the matrix\n",
    "tp, fp, fn, tn = confusion_matrix(y_test, y_pred,labels = [1,0]).ravel()\n",
    "# Print them out\n",
    "tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "Precision tells us how many of the correctly predicted cases actually turned out to be positive.<P>\n",
    "Intuitively, precision is the ability of the classifier to **not mislabel a true negative as a positive**.<P>\n",
    "\n",
    "The best value is 1 and the worst value is 0.<BR>\n",
    "<img src=\"images/precision.png\" width=200 height=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "# Manually calculate\n",
    "p = tp / (tp + fp)\n",
    "print('Precision:',p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "Recall tells us how many of the actual positive cases we were able to predict correctly with our model.<P>\n",
    "Intuitively, recall is the ability of the classifier to **find all the positive samples**.<P>\n",
    "The best value is 1 and the worst value is 0.<BR>\n",
    "<img src=\"images/recall.png\" width=200 height=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Manually calculate\n",
    "r = tp / (tp + fn)\n",
    "print('Recall:',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score\n",
    "F1-score is a harmonic mean of Precision and Recall, and so it gives a combined idea about these two metrics.<P>\n",
    "It is maximum value is 1 when Precision is equal to Recall.<BR>\n",
    "<img src=\"images/f1.png\" width=200 height=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "# Manually calculate\n",
    "f1 = 2 / ((1/r) + (1/p))\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "You can do it all with a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cancer      0.056     0.333     0.095         3\n",
      "   no cancer      0.989     0.914     0.950       197\n",
      "\n",
      "    accuracy                          0.905       200\n",
      "   macro avg      0.522     0.624     0.523       200\n",
      "weighted avg      0.975     0.905     0.937       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred, y_test,target_names = ['cancer','no cancer'], digits = 3, labels = [1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
