{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 8 Lab: Scaling Data Practice\n",
    "    \n",
    "Recall a few guidelines:\n",
    "- You don't scale the target variable (the 'y' or dependent variable. Leave it in its original scale)\n",
    "- You fit the scaler to only the training data (X_train), not the whole dataset\n",
    "- You must scale the test data (X_test) before you use the trained model to predict values\n",
    "\n",
    "In this lab:\n",
    "- Load the Ames, Iowa housing dataset from S3\n",
    "- Split the data into train and test sets\n",
    "- Scale X_train data using a normalized and standardized scaler\n",
    "- Use a new type of linear regression algorithm called a Stochastic Gradient Descent (SGD)\n",
    "    - You'll see a very large difference in model performance when you train using scaled data\n",
    "- Compare linear regression models for the 3 datasets: Unscaled, Normalized, Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model # This include the SGD algorithm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Ames, Iowa housing dataset from S3 into a pandas DataFrame\n",
    "This is a similar dataset to the Boston Housing, just bigger.\n",
    "\n",
    "The goal is to predict house sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the S3 bucket: machinelearning-read-only\n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/AmesHousing.csv'\n",
    "# Create session and S3 client\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3')\n",
    "# Load the dataframe\n",
    "response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "df = pd.read_csv(response.get(\"Body\")) \n",
    "print('The size of the complete dataset:',df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1A. Isolate the features and target variable\n",
    "For simplification, use only 2 features from the dataset:\n",
    "- 'Gr Liv Area' - size of the house in square feet\n",
    "- 'Overall Quality' - Rates the overall material and finish of the house\n",
    "\n",
    "Use 'SalePrice' for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the relevant variables\n",
    "X = df[['Gr Liv Area', 'Overall Qual']]\n",
    "y = df[['SalePrice']]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# notice the scale of the features\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the vastly different scales of the variables\n",
    "- Living area: 334 to 5642\n",
    "- Overall quality: 1 to 10\n",
    "\n",
    "This will make it hard for a linear regression algorithm to predict very accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "# Verify the sizes of the split datasets\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scale X_train data using a normalized and standardized scaler\n",
    "Store the scaled data in these pandas DataFrames\n",
    "- X_train_norm\n",
    "- X_train_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check:\n",
    "You should have 3 X_train DataFrames:\n",
    "- X_train: unscaled data\n",
    "- X_train_norm: normalized data\n",
    "- X_train_stand: standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the Stochastic Gradient Descent (SGD) algorithm\n",
    "Let's introduce a new type of linear regression algorithm called the SGD:<P>\n",
    "This is similar to a linear regression, but more sophosticated. It uses something called a \"loss function.\" As the algorithm trains, it continues to evaluate how well it is performing and adjusts accordingly to improve the predictions of the model.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor.score\n",
    "\n",
    "This algorithm is sensitive to features with differing scales. We will see big improvements as we scale the features into similar scales.<P>\n",
    "    \n",
    "For us at this stage, we can use it in a very similar way to the regular linear regression model. It is not as intuitive as a simple linear regression model, but it is more powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: When you train the SGD algorithm, it expects a 1d numpy array for the y values. Otherwise, you'll get a warning.\n",
    "# Convert y_train to a 1d numpy array before training the model\n",
    "y_train = y_train.values.ravel()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list to keep track of model performance\n",
    "model_performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, use just the unscaled data to train and evaluate the model\n",
    "#\n",
    "# Create linear regression object\n",
    "ori_SGD = linear_model.SGDRegressor() # We'll use the default hyperparameters\n",
    "#\n",
    "# Train the model using the training data. \n",
    "ori_SGD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscaled data continued.....\n",
    "#\n",
    "# Make predictions of sales price using the unscaled X_test data\n",
    "y_pred = ori_SGD.predict(X_test)\n",
    "# Have a look at the first few of the y_test and y_pred\n",
    "for row in range(4):\n",
    "    pp = int(y_pred[row]) # Pull out predicted price\n",
    "    tp = int(y_test.values[row].item()) # Pull out true price\n",
    "    error = abs(pp - tp)\n",
    "    print('Predicted price:', pp, 'True price:', tp, 'Error:', error)\n",
    "# Now, compute r2 and mse\n",
    "print('\\nUnscaled model performance:')\n",
    "r2 = round(r2_score(y_test, y_pred),2)\n",
    "mse = round(mean_squared_error(y_test, y_pred),2)\n",
    "print(\"Coefficient of determination: %.2f\" % r2)\n",
    "print(\"MSE:\",mse)\n",
    "# Store the results into the list\n",
    "model_performance.append(['unscaled',r2,mse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wow, big errors and negative R^2. Not a very good regression model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn:\n",
    "- In a similar way, train and evaluate the model using normalized and standardized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate using the normalized data\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate using the standardized data\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you stored your values in this list, show it now\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "What we did:<P>\n",
    "- Picked 2 \"intutive?\" features from 83 to predict sales price: size (sq. feet) and overall quality\n",
    "- Scaled the X_train data to both normalized and standarized scales.\n",
    "- Tried to use the unscaled data to train the SGD algorithm. It failed.\n",
    "- Trained the SGD algorithm on both the normalized and standardized data and saw a big improvement.<BR>\n",
    "<BR>\n",
    "If we wanted a better model, we could perform feature selection and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
