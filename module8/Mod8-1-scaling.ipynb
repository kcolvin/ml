{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 8-1 Learning Notebook: Scaling Data\n",
    "\n",
    "The importance of Data Scaling:<P>\n",
    "\n",
    "It is common to have data where the scale of values differs from variable to variable. For example, one variable may be in feet, another in meters, or one may be in lbs and another in percent body fat, etc.\n",
    "\n",
    "In some machine learning algorithms, we can achieve much better performance if all of the variables are scaled in similar or the same range. Common scaling ranges are:\n",
    "- <B>\"normalization\"</B>: scale everything on the interval of  0 - 1\n",
    "    \n",
    "<img src=\"images/norm.png\" alt=\"Normalization\" style=\"width: 700px;\"/>    \n",
    "    \n",
    "- <B>\"standardization\"</B>: scale so the the data has a standard deviation of 1 and mean centered on 0\n",
    "\n",
    "<img src=\"images/stand.png\" alt=\"Standardization\" style=\"width: 700px;\"/><BR>    \n",
    "Scaling often improves the performance of parametric  algorithms that use a weighted sum of the input, like linear models and neural networks, as well as models that use distance measures such as Support Vector Machines (SVMs) and K-Nearest Neighbors (KNNs). We will learn these algorithms soon.\n",
    "    \n",
    "Some algorithms, like decision trees are not sensitive to scaled data, but it doesn't hurt to scale the data.\n",
    "\n",
    "As such, it is a good practice to scale input data. This lesson is about scaling data.\n",
    "    \n",
    "A few guidelines:\n",
    "- You don't scale the target variable (the 'y' or dependent variable. Leave it in its original scale)\n",
    "- You fit the scaler to only the training data (X_train), not the whole dataset\n",
    "- You must scale the test data (X_test) before you use the trained model to predict values\n",
    "\n",
    "In this exercise, we will:\n",
    "- Load very small diabetes dataset\n",
    "- Split the data into train and test sets\n",
    "- Demonstrate scaling X_train data using a normalized and standardized scaler\n",
    "- Compare multiple linear regressions on scaled data\n",
    "- Discuss why we don't see model improvement in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the complete dataset: (20, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Waist  Pulse\n",
       "0   191.0   36.0   50.0\n",
       "1   189.0   37.0   52.0\n",
       "2   193.0   38.0   58.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data from the S3 bucket: machinelearning-read-only\n",
    "# Create session and S3 client\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3')\n",
    "# Set variables \n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/diabetes.csv'\n",
    "# Load the dataframe\n",
    "response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "# The 'Body' is of type streaming body. We can put this right into a dataframe\n",
    "df = pd.read_csv(response.get(\"Body\")) \n",
    "print('The size of the complete dataset:',df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>178.600000</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>56.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.690505</td>\n",
       "      <td>3.201973</td>\n",
       "      <td>7.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>138.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>160.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>51.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>191.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>60.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>247.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Weight      Waist      Pulse\n",
       "count   20.000000  20.000000  20.000000\n",
       "mean   178.600000  35.400000  56.100000\n",
       "std     24.690505   3.201973   7.210373\n",
       "min    138.000000  31.000000  46.000000\n",
       "25%    160.750000  33.000000  51.500000\n",
       "50%    176.000000  35.000000  55.000000\n",
       "75%    191.500000  37.000000  60.500000\n",
       "max    247.000000  46.000000  74.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the descriptive stats of the raw data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features and target dataframes\n",
    "X = df[['Weight','Pulse']]\n",
    "y = df['Waist'] \n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 44)\n",
    "# We are going to train the scaler using the X_train data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Demonstrate scaling X_train data using a normalized and standardized scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25688073, 0.21428571],\n",
       "       [0.16513761, 0.28571429],\n",
       "       [0.46788991, 0.21428571],\n",
       "       [0.66972477, 0.35714286],\n",
       "       [0.14678899, 0.64285714],\n",
       "       [0.26605505, 0.5       ],\n",
       "       [0.34862385, 1.        ],\n",
       "       [0.28440367, 0.14285714],\n",
       "       [0.34862385, 0.28571429],\n",
       "       [0.46788991, 0.        ],\n",
       "       [0.48623853, 0.14285714],\n",
       "       [0.        , 0.78571429],\n",
       "       [1.        , 0.14285714],\n",
       "       [0.17431193, 0.21428571],\n",
       "       [0.22018349, 0.57142857]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization scaler: scale all columns to 0 - 1 intervals\n",
    "# Import the MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Create the object\n",
    "norm_scaler = MinMaxScaler()\n",
    "# Compute the minimum and maximum to be used for later scaling.\n",
    "norm_scaler.fit(X_train)\n",
    "# Do the scaling, this returns a numpy array\n",
    "norm_scaled_array = norm_scaler.transform(X_train) \n",
    "norm_scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.353517</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.244454</td>\n",
       "      <td>0.277781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.197248</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.284404</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Weight      Pulse\n",
       "count  15.000000  15.000000\n",
       "mean    0.353517   0.366667\n",
       "std     0.244454   0.277781\n",
       "min     0.000000   0.000000\n",
       "25%     0.197248   0.178571\n",
       "50%     0.284404   0.285714\n",
       "75%     0.467890   0.535714\n",
       "max     1.000000   1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a dataframe out of the array\n",
    "X_train_norm = pd.DataFrame(data = norm_scaled_array, columns = X_train.columns)\n",
    "# And check out the descriptive stats\n",
    "X_train_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.401487e-17</td>\n",
       "      <td>1.258253e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035098e+00</td>\n",
       "      <td>1.035098e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.496907e+00</td>\n",
       "      <td>-1.366314e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.616951e-01</td>\n",
       "      <td>-7.009013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.926479e-01</td>\n",
       "      <td>-3.016537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.842935e-01</td>\n",
       "      <td>6.299239e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.737423e+00</td>\n",
       "      <td>2.359997e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Weight         Pulse\n",
       "count  1.500000e+01  1.500000e+01\n",
       "mean   7.401487e-17  1.258253e-16\n",
       "std    1.035098e+00  1.035098e+00\n",
       "min   -1.496907e+00 -1.366314e+00\n",
       "25%   -6.616951e-01 -7.009013e-01\n",
       "50%   -2.926479e-01 -3.016537e-01\n",
       "75%    4.842935e-01  6.299239e-01\n",
       "max    2.737423e+00  2.359997e+00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardized scaler: scale all columns to std dev = 1 & centered at 0\n",
    "# Import the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create the object\n",
    "stand_scaler = StandardScaler()\n",
    "# Compute the standard deviation and current mean to be used for later scaling.\n",
    "stand_scaler.fit(X_train)\n",
    "# Do the scaling, this returns a numpy array\n",
    "stand_scaled_array = stand_scaler.transform(X_train) \n",
    "# Create a dataframe out of the array\n",
    "X_train_stand = pd.DataFrame(data = stand_scaled_array, columns = X_train.columns)\n",
    "X_train_stand.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare multiple linear regressions on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of model performance\n",
    "model_performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled model performance:\n",
      "The linear model has equation of:\n",
      "y = 0.11324628938445999 * x1 + -0.024528558257205475 * x2 + 16.588395258602095\n",
      "Coefficient of determination: 0.73\n",
      "MSE: 0.75\n"
     ]
    }
   ],
   "source": [
    "# First, use just the unscaled data\n",
    "#\n",
    "# Create linear regression object\n",
    "ori_model = linear_model.LinearRegression()\n",
    "#\n",
    "# Train the model using the training sets\n",
    "ori_model.fit(X_train, y_train)\n",
    "#\n",
    "print('Unscaled model performance:')\n",
    "print('The linear model has equation of:')\n",
    "x1_coef = ori_model.coef_.item(0)\n",
    "x2_coef = ori_model.coef_.item(1)\n",
    "intercept = ori_model.intercept_.item(0)\n",
    "print(\"y = {} * x1 + {} * x2 + {}\".format(x1_coef,x2_coef,intercept))\n",
    "# Make predictions of waist size using weights from the test dataset\n",
    "y_pred = ori_model.predict(X_test)\n",
    "# Now, use the waist size prediction and the true waist size to see how well our model does\n",
    "r2 = round(r2_score(y_test, y_pred),2)\n",
    "mse = round(mean_squared_error(y_test, y_pred),2)\n",
    "print(\"Coefficient of determination: %.2f\" % r2)\n",
    "print(\"MSE:\",mse)\n",
    "model_performance.append(['unscaled',r2,mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized model performance:\n",
      "The linear model has equation of:\n",
      "y = 12.343845542906138 * x1 + -0.686799631201753 * x2 + 31.08806951382612\n",
      "Coefficient of determination: 0.73\n",
      "MSE: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Second, normalized data\n",
    "#\n",
    "# Create linear regression object\n",
    "norm_model = linear_model.LinearRegression()\n",
    "#\n",
    "# Train the model using the normalized features original targets\n",
    "norm_model.fit(X_train_norm, y_train)\n",
    "#\n",
    "print('Normalized model performance:')\n",
    "print('The linear model has equation of:')\n",
    "x1_coef = norm_model.coef_.item(0)\n",
    "x2_coef = norm_model.coef_.item(1)\n",
    "intercept = norm_model.intercept_.item(0)\n",
    "print(\"y = {} * x1 + {} * x2 + {}\".format(x1_coef,x2_coef,intercept))\n",
    "# *******\n",
    "# We must NORMALIZE (or \"transform\") test data to use it on this model\n",
    "X_test_norm = norm_scaler.transform(X_test) # We are using the same scaler we created earlier\n",
    "y_pred = norm_model.predict(X_test_norm) # Now we can predict using the scaled data\n",
    "# *******\n",
    "# Now, use the waist size prediction and the true waist size to see how well our model does\n",
    "r2 = round(r2_score(y_test, y_pred),2)\n",
    "mse = round(mean_squared_error(y_test, y_pred),2)\n",
    "print(\"Coefficient of determination: %.2f\" % r2)\n",
    "print(\"MSE:\",mse)\n",
    "model_performance.append(['normalized',r2,mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized model performance:\n",
      "The linear model has equation of:\n",
      "y = 2.915182296690269 * x1 + -0.18431089389555544 * x2 + 35.2\n",
      "Coefficient of determination: 0.73\n",
      "MSE: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Third, standardized data\n",
    "#\n",
    "# Create linear regression object\n",
    "stand_model = linear_model.LinearRegression()\n",
    "#\n",
    "# Train the model using the normalized features original targets\n",
    "stand_model.fit(X_train_stand, y_train)\n",
    "#\n",
    "print('Standardized model performance:')\n",
    "print('The linear model has equation of:')\n",
    "x1_coef = stand_model.coef_.item(0)\n",
    "x2_coef = stand_model.coef_.item(1)\n",
    "intercept = stand_model.intercept_.item(0)\n",
    "print(\"y = {} * x1 + {} * x2 + {}\".format(x1_coef,x2_coef,intercept))\n",
    "# *******\n",
    "# We must STANDARDIZE (or \"transform\") test data to use it on this model\n",
    "X_test_stand = stand_scaler.transform(X_test) # We are using the same scaler we created earlier\n",
    "y_pred = stand_model.predict(X_test_stand) # Now we can predict using the scaled data\n",
    "# *******\n",
    "# Now, use the waist size prediction and the true waist size to see how well our model does\n",
    "r2 = round(r2_score(y_test, y_pred),2)\n",
    "mse = round(mean_squared_error(y_test, y_pred),2)\n",
    "print(\"Coefficient of determination: %.2f\" % r2)\n",
    "print(\"MSE:\",mse)\n",
    "model_performance.append(['standardized',r2,mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unscaled', 0.73, 0.75],\n",
       " ['normalized', 0.73, 0.75],\n",
       " ['standardized', 0.73, 0.75]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show comparisions: Why don't we see improvement?\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to transform before making predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model: [39.04557388]\n",
      "Normalized model: [39.04557388]\n",
      "Standardized model: [39.04557388]\n"
     ]
    }
   ],
   "source": [
    "# Predict my waist size\n",
    "myData = [[210,54]]\n",
    "print('Original model:', ori_model.predict(myData))\n",
    "print('Normalized model:', norm_model.predict(norm_scaler.transform(myData)))\n",
    "print('Standardized model:', stand_model.predict(stand_scaler.transform(myData)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
