{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 10 Lab: Practice preparing data for a classification algorithm\n",
    "\n",
    "In this dataset, we want to look at abalone physical measurements to predict if it is an adult or youth.<P>\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/abalone\n",
    "\n",
    "The data needs a little preparation before we can use it. <P>\n",
    "    \n",
    "Data Columns:\n",
    "- sex: Male/Female (str)\n",
    "- length: mm (float)\n",
    "- diameter: mm (float)\n",
    "- height: mm (float)\n",
    "- whole weight: grams (float)\n",
    "- shucked weight: grams (float)\n",
    "- viscera (guts) weight: grams (float)\n",
    "- shell weight: grams (float)\n",
    "    \n",
    "Target:    \n",
    "- age in years (integer)\n",
    "    \n",
    "Problems we have to fix:\n",
    "- convert sex column to: male = 0, female = 1\n",
    "- make new column for our target:\n",
    "    - if age <= 9, then youth = 0\n",
    "    - if age > 9, then adult = 1\n",
    "- Remove 'age' column\n",
    "    \n",
    "Save the cleaned file to your folder on S3. We will use it in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup boto3\n",
    "sess = boto3.session.Session()\n",
    "s3 = sess.client('s3') \n",
    "# Define the bucket & file you want to load\n",
    "source_bucket = 'machinelearning-read-only'\n",
    "source_key = 'data/abalone_raw.csv'\n",
    "#\n",
    "response = s3.get_object(Bucket=source_bucket, Key=source_key)\n",
    "#\n",
    "# Load the 'data' part of the response directly into a dataframe\n",
    "df = pd.read_csv(response.get(\"Body\"))\n",
    "# Let's leave df in place and make a copy of it to work with\n",
    "df_cleaned = df\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datatypes and any missing values\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert 'sex' (currently a string column) to a numeric column\n",
    "- Male = 0\n",
    "- Female = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a new binary integer column called 'target'\n",
    "- If age <= 9, then target = 0\n",
    "- If age > 9, then target = 1\n",
    "\n",
    "Hint: One way is to use the np.where() function from the teaching notebook. There are other ways too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Drop the 'age' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Verify your work\n",
    "Is the dataset ready for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save your file to your folder on the S3 bucket\n",
    "\n",
    "- destination_bucket = 'machinelearning-shared' # Same as before\n",
    "- destination_key = 'data/your username/abalone_clean.XXX' # Customize for your use\n",
    "    \n",
    "You decide what format to save the data. Could be .csv or .pkl or ?? You'll have to load it again in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify your file exists where you think it does:\n",
    "#\n",
    "response = s3.list_objects(Bucket = destination_bucket)\n",
    "# Parse though the response\n",
    "#\n",
    "my_folder = 'kcolvin'  # Change for your folder\n",
    "#\n",
    "for object in response['Contents']:\n",
    "    if my_folder in object['Key']:\n",
    "        print(object['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
